# -*- coding: utf-8 -*-
"""Final_Image-Based_Malware_Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VAZME7ZjS96gEK7BNUoyavCOA2CgmDR6
"""

import numpy as np
import tensorflow as tf
from keras.utils import to_categorical
import pandas as pd
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from keras.layers import Dropout
from keras.callbacks import EarlyStopping
from skimage.transform import resize
from sklearn.metrics import confusion_matrix
import seaborn as sns
from PIL import Image
import cv2
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

data = pd.read_csv('/content/drive/MyDrive/firmware.csv')
data = data.iloc[:,:-1]

data.head()

pixel_data = data.iloc[:, 3:].values

# check if data size is a multiple of 1024
if pixel_data.size % 1024 != 0:
    raise ValueError("not a multiple of 1024")

num_images = pixel_data.shape[0]
pixels = pixel_data.reshape(num_images, 32, 32, 1) / 255.0
targets = to_categorical(data['target'].values)

x_train, x_test, y_train, y_test = train_test_split(pixels, targets, test_size=0.35, random_state=42)

# build the model
model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 1)))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.5))
model.add(Flatten())
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(len(np.unique(data['target'])), activation='softmax'))

# compile the model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
earlystop = EarlyStopping(monitor='val_loss', min_delta=0.005, patience=1, verbose=0, mode='auto')

# fit the model
model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test), callbacks=[earlystop])

# evaluation
loss, accuracy = model.evaluate(x_test, y_test)
print('loss:', loss)
print('accuracy:', accuracy)

# now let's obfuscate
def add_noise(dataset, noise_factor=0.4):
    dataset_noisy = dataset + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=dataset.shape)
    dataset_noisy = np.clip(dataset_noisy, 0., 1.)
    return dataset_noisy

pixels_add_noise = add_noise(pixels)

def blur_images(images, kernel_size=(5, 5)):
    blurred_images = np.empty(images.shape)
    for i, img in enumerate(images):
        img_2d = img.reshape(img.shape[:-1])
        blurred_img_2d = cv2.GaussianBlur(img_2d, kernel_size, 0)
        blurred_images[i] = blurred_img_2d.reshape(img.shape)
    return blurred_images

pixels_blurred = blur_images(pixels_add_noise)

def pixelate_images(images, reduction_factor=0.6):
    pixelated_images = np.empty(images.shape)
    for i, img in enumerate(images):
        img_2d = img.reshape(img.shape[:-1])
        small_img_2d = resize(img_2d, (int(img_2d.shape[0] * reduction_factor), int(img_2d.shape[1] * reduction_factor)), mode='reflect')
        pixelated_img_2d = resize(small_img_2d, img_2d.shape, mode='reflect')
        pixelated_images[i] = pixelated_img_2d.reshape(img.shape)
    return pixelated_images

pixels_pixelated = pixelate_images(pixels_blurred)

# split the noisy data
x_train_noisy, x_test_noisy, y_train_noisy, y_test_noisy = train_test_split(pixels_pixelated, targets, test_size=0.35, random_state=42)

# build the model
model_obf = Sequential()
model_obf.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 1)))
model_obf.add(MaxPooling2D(pool_size=(2, 2)))
model_obf.add(Dropout(0.5))
model_obf.add(Flatten())
model_obf.add(Dense(64, activation='relu'))
model_obf.add(Dropout(0.5))
model_obf.add(Dense(len(np.unique(data['target'])), activation='softmax'))

# compile the model
model_obf.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# fit the model
earlystop = EarlyStopping(monitor='val_loss', min_delta=0.005, patience=1, verbose=0, mode='auto')
model_obf.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test), callbacks=[earlystop])

# evaluation
loss_noisy, accuracy_noisy = model_obf.evaluate(x_test_noisy, y_test_noisy)
print('loss with noisy data:', loss_noisy)
print('accuracy with noisy data:', accuracy_noisy)

# confusion matrix
y_pred = model.predict(x_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test, axis=1)
confusion_mtx = confusion_matrix(y_true, y_pred_classes)
plt.figure(figsize=(10,8))
sns.heatmap(confusion_mtx, annot=True, fmt='d', cmap=plt.cm.Blues)
plt.title("confusion matrix")
plt.ylabel('true label')
plt.xlabel('predicted label')
plt.show()

class_counts = dict()

temp_pixel_data = None
temp_class_name = None

for pixel_data, class_name in zip(pixels, data['class']):
    
    pixel_data = np.squeeze(pixel_data)

    class_counts[class_name] = class_counts.get(class_name, 0) + 1
    if class_counts[class_name] > 5:
        continue
    
    if temp_pixel_data is None:
        temp_pixel_data = pixel_data
        temp_class_name = class_name
    else:
        fig, axs = plt.subplots(1, 2, figsize=(10, 5))

        axs[0].set_title(f"{temp_class_name} - Image {class_counts[temp_class_name]}")
        axs[0].imshow(temp_pixel_data, cmap='gray')

        axs[1].set_title(f"{class_name} - Image {class_counts[class_name]}")
        axs[1].imshow(pixel_data, cmap='gray')

        plt.show()

        temp_pixel_data = None
        temp_class_name = None